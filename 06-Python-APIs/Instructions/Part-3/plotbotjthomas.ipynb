{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tweepy\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import pprint as pp\n",
    "\n",
    "#Set variable for datetime for plots\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "\n",
    "# Import and Initialize Sentiment Analyzer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "#load twitter api keys\n",
    "from config import consumer_key, consumer_secret, access_token, access_token_secret\n",
    "\n",
    "# Setup Tweepy API Authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "[{'message': 'Rate limit exceeded', 'code': 88}]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-03529986119f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m#Search recent tweets to search for mentions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mpublic_tweet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"recent\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpublic_tweet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'statuses'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tweepy\\binder.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    248\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tweepy\\binder.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mis_rate_limit_error_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mRateLimitError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mTweepError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapi_code\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mapi_error_code\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRateLimitError\u001b[0m: [{'message': 'Rate limit exceeded', 'code': 88}]"
     ]
    }
   ],
   "source": [
    "#Set search term to search for @plotblot and setup previously searched list\n",
    "keyword = \"@PlotBot\"\n",
    "previously_searched = []\n",
    "\n",
    "while(True):\n",
    "    #Setup lists for  usernames, mention, username, sentiment_user\n",
    "    mention =[]\n",
    "    username = []\n",
    "    sentiment_user = []\n",
    "\n",
    "    #Search recent tweets to search for mentions \n",
    "    public_tweet = api.search(keyword, count = 10, results_type = \"recent\")\n",
    "\n",
    "    if public_tweet['statuses']:   \n",
    "        for tweet in public_tweet['statuses']:\n",
    "            mention = tweet['entities']['user_mentions'][1]['screen_name']\n",
    "            username = tweet['user']['screen_name']\n",
    "            if mention not in previously_searched:\n",
    "                previously_searched.append(mention)\n",
    "                sentiment_user.append(mention)\n",
    "    #I basically cut and pasted this from the classroom Vader Tweet Excercise but instead of getting means captured all scores\n",
    "\n",
    "    # List for dictionaries of results\n",
    "    results_list = []\n",
    "    compound_list = []\n",
    "    positive_list = []\n",
    "    negative_list = []\n",
    "    neutral_list = []\n",
    "    tweetsago_list = []\n",
    "\n",
    "    # Loop through each user\n",
    "    counter = 0\n",
    "    for user in sentiment_user:\n",
    "\n",
    "\n",
    "        # Loop through 25 pages of tweets (total 500 tweets)\n",
    "        for x in range(1, 26):\n",
    "\n",
    "            # Get all tweets from home feed\n",
    "            public_tweets = api.user_timeline(user, page=x)\n",
    "\n",
    "            # Loop through all tweets\n",
    "            for tweet in public_tweets:\n",
    "\n",
    "                # Run Vader Analysis on each tweet\n",
    "                results = analyzer.polarity_scores(tweet[\"text\"])\n",
    "                compound = results[\"compound\"]\n",
    "                pos = results[\"pos\"]\n",
    "                neu = results[\"neu\"]\n",
    "                neg = results[\"neg\"]\n",
    "\n",
    "                # Add each value to the appropriate list\n",
    "                compound_list.append(compound)\n",
    "                positive_list.append(pos)\n",
    "                negative_list.append(neg)\n",
    "                neutral_list.append(neu)\n",
    "                counter=counter-1\n",
    "                tweetsago_list.append(counter)\n",
    "\n",
    "\n",
    "        # Create a dictionaty of results\n",
    "        user_results = {\n",
    "            \"Username\": user,\n",
    "            \"Compound Score\": (compound_list),\n",
    "            \"Postive Score\": (positive_list),\n",
    "            \"Neutral Score\": (neutral_list),\n",
    "            \"Negative Score\": (negative_list),\n",
    "            \"Tweets Ago\":(tweetsago_list)\n",
    "        }\n",
    "\n",
    "        # Append dictionary to list\n",
    "        results_list.append(user_results)\n",
    "\n",
    "        #Convert results list to dataframe for plotting\n",
    "        results_list_df = pd.DataFrame.from_dict(user_results).round(3)\n",
    "\n",
    "        #Plot tweet_sentiment\n",
    "        tweet_sentiment_plt = results_list_df.plot(x='Tweets Ago', y='Compound Score', marker ='.',\n",
    "                                        markersize=10, color='blue', label=f'@{user}',\n",
    "                                        linewidth=.5)\n",
    "\n",
    "        tweet_sentiment_plt.legend(bbox_to_anchor=(1, 1), frameon=False, title=\"Tweets by\")\n",
    "        tweet_sentiment_plt.set_ylabel('Tweet Polarity')\n",
    "        tweet_sentiment_plt.set_xlabel('Tweets Ago')\n",
    "        tweet_sentiment_plt.set_title(f\"Sentiment Analysis of Tweets ({now.strftime('%m/%d/%Y')})\")\n",
    "        tweet_sentiment_plt.yaxis.grid(True)\n",
    "        plt.autoscale(enable=True, axis='x')\n",
    "        plt.savefig(\"Images/Analysis.png\", bbox_inches='tight')\n",
    "        plt.show()\n",
    "        api.update_with_media('Images/Analysis.png',f\"Tweet Analysis for @{user}, requested by @{username}\")   \n",
    "        time.sleep(300)\n",
    "\n",
    "    \n",
    "   \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
