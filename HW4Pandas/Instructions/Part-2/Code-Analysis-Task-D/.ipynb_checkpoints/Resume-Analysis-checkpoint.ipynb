{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resume Analysis\n",
    "_**HARD: This is a curveball assignment. Plus, this is Python without Pandas.**_\n",
    "\n",
    "#### The objective of this assignment is for you to explain what is happening in each cell in clear, understandable language. \n",
    "\n",
    "#### _There is no need to code._ The code is there for you, and it already runs. Your task is only to explain what each line in each cell does.\n",
    "\n",
    "#### The placeholder cells should describe what happens in the cell below it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below imports `os` as a dependency because the `os.path.join` function. Also, the `string` dependency is needed because later in the script, `string.punctuation` will be used to detect and remove punctuation symbols. Explain what the line `from collection import Counter` does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is using the os library .path.join to set the location to the file which is one up from the root where the script is running \".\" and named resume.md. \n",
    "\n",
    "It then creates two dictionarys with string values for required skils and desired skills as keys but no values. These dictionaries can be used to search the resume file for matches later on. The dictionaries are in all caps as the are constants/will not be changing. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "resume_path = os.path.join(\".\", 'resume.md')\n",
    "\n",
    "# Skills to match\n",
    "REQUIRED_SKILLS = {\"excel\", \"python\", \"mysql\", \"statistics\"}\n",
    "DESIRED_SKILLS = {\"r\", \"git\", \"html\", \"css\", \"leaflet\", \"modeling\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is defining a new function called load_file. It takes in the file and creates three lists that read in the entire resume, converts the contents to lower case, and then splits in into indlvidual words which is stored in a list called \"resume tokens\" which is then returned. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(filepath):\n",
    "    # Helper function to read a file and return the data.\n",
    "    with open(filepath, \"r\") as resume_file_handler:\n",
    "        resume_contents = resume_file_handler.read()\n",
    "        resume_contents = resume_contents.lower()\n",
    "        resume_tokens = resume_contents.split()\n",
    "        return resume_tokens\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a word_list list using the load_file function defined earlier. The resume_tokens list of lowercase split words is input into word list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#',\n",
       " 'frank',\n",
       " 'n.',\n",
       " 'stein',\n",
       " '##',\n",
       " 'education',\n",
       " '*',\n",
       " 'data',\n",
       " 'analytics',\n",
       " 'and',\n",
       " 'visualization',\n",
       " 'boot',\n",
       " 'camp',\n",
       " 'graduate',\n",
       " '##',\n",
       " 'experience',\n",
       " '*',\n",
       " 'creating',\n",
       " 'pivot',\n",
       " 'tables',\n",
       " 'and',\n",
       " 'vba',\n",
       " 'scripts',\n",
       " 'in',\n",
       " 'excel.',\n",
       " '*',\n",
       " 'modeling',\n",
       " 'and',\n",
       " 'forecasting',\n",
       " 'data',\n",
       " 'using',\n",
       " 'basic',\n",
       " 'statistics',\n",
       " '*',\n",
       " 'writing',\n",
       " 'python',\n",
       " 'scripts',\n",
       " 'to',\n",
       " 'analyze',\n",
       " 'data',\n",
       " 'sets',\n",
       " 'from',\n",
       " 'files',\n",
       " 'and',\n",
       " 'apis.',\n",
       " '*',\n",
       " 'social',\n",
       " 'media',\n",
       " 'mining',\n",
       " 'using',\n",
       " 'python',\n",
       " '*',\n",
       " 'working',\n",
       " 'with',\n",
       " 'mysql',\n",
       " 'and',\n",
       " 'mongodb',\n",
       " 'databases',\n",
       " '*',\n",
       " 'developing',\n",
       " 'front-end',\n",
       " 'web',\n",
       " 'visualizations',\n",
       " 'using',\n",
       " 'html,',\n",
       " 'css,',\n",
       " 'bootstrap,',\n",
       " 'd3,',\n",
       " 'and',\n",
       " 'leaflet.js',\n",
       " '*',\n",
       " 'using',\n",
       " 'the',\n",
       " 'tableau',\n",
       " 'business',\n",
       " 'intelligence',\n",
       " 'software',\n",
       " '*',\n",
       " 'performing',\n",
       " 'big',\n",
       " 'data',\n",
       " 'analytics',\n",
       " 'with',\n",
       " 'hadoop',\n",
       " '*',\n",
       " 'working',\n",
       " 'with',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'algorithms',\n",
       " '##',\n",
       " 'skills',\n",
       " '*',\n",
       " 'microsoft',\n",
       " 'excel,',\n",
       " 'python,',\n",
       " 'javascript,',\n",
       " 'html/css,',\n",
       " 'api',\n",
       " 'interactions,',\n",
       " 'social',\n",
       " 'media',\n",
       " 'mining,',\n",
       " 'sql,',\n",
       " 'hadoop,',\n",
       " 'tableau,',\n",
       " 'advanced',\n",
       " 'statistics,',\n",
       " 'machine',\n",
       " 'learning,',\n",
       " 'r,',\n",
       " 'git/github',\n",
       " '##',\n",
       " 'interests',\n",
       " '*',\n",
       " 'contributing',\n",
       " 'to',\n",
       " 'open-source',\n",
       " 'software',\n",
       " '*',\n",
       " 'data',\n",
       " 'analytics',\n",
       " 'with',\n",
       " 'python',\n",
       " 'and',\n",
       " 'pandas',\n",
       " '*',\n",
       " 'designing',\n",
       " 'data',\n",
       " 'visualization',\n",
       " 'web',\n",
       " 'apps',\n",
       " 'with',\n",
       " 'html,',\n",
       " 'css,',\n",
       " 'javascript,',\n",
       " 'and',\n",
       " 'd3',\n",
       " '*',\n",
       " 'working',\n",
       " 'with',\n",
       " 'big',\n",
       " 'data',\n",
       " 'in',\n",
       " 'the',\n",
       " 'cloud',\n",
       " 'using',\n",
       " 'aws']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab the text for a Resume\n",
    "word_list = load_file(resume_path)\n",
    "word_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Replace this with your clear explanation of what happens in the cell below. \n",
    "Be sure to answer the following:\n",
    "* Why is a `set` created?\n",
    "\n",
    "   This is creating a set called \"resume\" which is an unordered collection  unique elements. This set can then be manipulated to see if it intersects/differs/etc. from other sets. \n",
    "   \n",
    "* How are we populating the set\n",
    "  \n",
    "  \n",
    "  We are using a for loop to iterate through the word_list created earlier adding each entry to the resume set. \n",
    "    \n",
    "* Why would it be necessary to create a `punctuation` set?\n",
    "    If punctuation is abuting words like \"excel,\" we will not be able to test the set for membership properly. \n",
    "\n",
    "* What does subtracting from the set do?\n",
    "\n",
    "   It removes all the punctiation form the set based on the list of punctation. \n",
    "   \n",
    "* * Refer to the `resume = resume - punctuation` line\n",
    "* What does `\\n` do in a string\n",
    "\n",
    " It adds a new line before printing the string to improve formatting. \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WORDS BEFORE MOVING PUNCTUATION\n",
      "{'python,', '*', 'big', 'algorithms', 'frank', 'css,', 'graduate', 'experience', 'visualization', 'bootstrap,', 'html,', 'interactions,', 'stein', 'git/github', 'camp', 'developing', 'javascript,', 'pandas', 'social', 'api', 'boot', 'performing', 'hadoop', 'the', 'r,', 'python', 'analyze', 'and', 'excel.', 'microsoft', 'aws', 'education', 'using', 'machine', 'working', 'interests', 'html/css,', 'contributing', 'apps', 'tables', 'creating', 'tableau,', 'vba', '##', 'data', 'apis.', 'd3,', 'media', 'databases', 'analytics', 'writing', 'files', 'open-source', 'pivot', 'mining', 'tableau', 'business', 'intelligence', 'skills', 'forecasting', 'statistics', 'visualizations', '#', 'hadoop,', 'modeling', 'leaflet.js', 'mysql', 'learning', 'designing', 'learning,', 'advanced', 'with', 'front-end', 'sql,', 'mongodb', 'from', 'mining,', 'to', 'in', 'scripts', 'statistics,', 'd3', 'n.', 'cloud', 'basic', 'excel,', 'sets', 'software', 'web'}\n",
      "\n",
      "WORDS AFTER MOVING PUNCTUATION\n",
      "{'python,', 'big', 'algorithms', 'frank', 'css,', 'graduate', 'experience', 'visualization', 'bootstrap,', 'interactions,', 'html,', 'stein', 'git/github', 'camp', 'developing', 'javascript,', 'pandas', 'social', 'api', 'boot', 'performing', 'hadoop', 'the', 'r,', 'python', 'analyze', 'and', 'excel.', 'microsoft', 'aws', 'education', 'using', 'machine', 'working', 'interests', 'html/css,', 'contributing', 'apps', 'tables', 'creating', 'tableau,', 'vba', '##', 'data', 'apis.', 'd3,', 'media', 'databases', 'analytics', 'writing', 'files', 'open-source', 'pivot', 'mining', 'tableau', 'business', 'intelligence', 'skills', 'forecasting', 'statistics', 'visualizations', 'hadoop,', 'modeling', 'leaflet.js', 'mysql', 'learning', 'designing', 'learning,', 'advanced', 'with', 'front-end', 'sql,', 'mongodb', 'from', 'mining,', 'to', 'in', 'scripts', 'statistics,', 'd3', 'n.', 'cloud', 'basic', 'excel,', 'sets', 'software', 'web'}\n"
     ]
    }
   ],
   "source": [
    "# Create a set of unique words from the resume\n",
    "resume = set()\n",
    "\n",
    "# HINT: Single elements in a programming language are often referred to as tokens\n",
    "for token in word_list:\n",
    "    resume.add(token)\n",
    "\n",
    "print('\\nWORDS BEFORE MOVING PUNCTUATION')    \n",
    "print(resume)\n",
    "\n",
    "# Remove Punctuation that were read as whole words\n",
    "punctuation = set(string.punctuation)\n",
    "# HINT: Attributes that are in `resume` that are not in `punctuation` (difference)\n",
    "resume = resume - punctuation\n",
    "\n",
    "print('\\nWORDS AFTER MOVING PUNCTUATION')    \n",
    "print(resume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace this with your clear explanation of what happens in the cell below. \n",
    "Be sure to answer the following:\n",
    "* What does using a `set` intersection do in this section?\n",
    "\n",
    "   It starts by printing out the values of the \"REQUIRED_SKILLS\" set.  It sees which values are in both the constant \"REQUIRED_SKILLS\" and the scrubbed resume set we created. It prints out the result. \n",
    "\n",
    "* How does the character cleaning function work differently than the word cleaning function? (test it)\n",
    "    \n",
    "    The word cleaning function works similarly to the set intersection by looking for entries not in the punctaion list generated earlier. It removes word tokens which match punctuation exactly. The character one goes through character by character and removes all the punctuation by only outputting values not in string.punctuation. The word one misses items that are not in the punctuation list such as ## so I would use character to truly scrub  the resume. \n",
    "\n",
    "\n",
    "\n",
    "* Can you add more items to the `stop_words` list?\n",
    "\n",
    "   Yes, it can be modified to look for more words. \n",
    "   \n",
    "* Explain how the list `word_list` list comprehension works. What does it return and what is the filtering criteria?\n",
    "\n",
    "It just iterates through the resume and returns only words that are not in the stop words list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REQUIRED SKILLS\n",
      "{'python', 'statistics', 'mysql'}\n",
      "DESIRED SKILLS\n",
      "{'modeling'}\n",
      "\n",
      "WORD LIST AFTER PUNCTUATION REMOVAL\n",
      "['frank', 'n.', 'stein', '##', 'education', 'data', 'analytics', 'and', 'visualization', 'boot', 'camp', 'graduate', '##', 'experience', 'creating', 'pivot', 'tables', 'and', 'vba', 'scripts', 'in', 'excel.', 'modeling', 'and', 'forecasting', 'data', 'using', 'basic', 'statistics', 'writing', 'python', 'scripts', 'to', 'analyze', 'data', 'sets', 'from', 'files', 'and', 'apis.', 'social', 'media', 'mining', 'using', 'python', 'working', 'with', 'mysql', 'and', 'mongodb', 'databases', 'developing', 'front-end', 'web', 'visualizations', 'using', 'html,', 'css,', 'bootstrap,', 'd3,', 'and', 'leaflet.js', 'using', 'the', 'tableau', 'business', 'intelligence', 'software', 'performing', 'big', 'data', 'analytics', 'with', 'hadoop', 'working', 'with', 'machine', 'learning', 'algorithms', '##', 'skills', 'microsoft', 'excel,', 'python,', 'javascript,', 'html/css,', 'api', 'interactions,', 'social', 'media', 'mining,', 'sql,', 'hadoop,', 'tableau,', 'advanced', 'statistics,', 'machine', 'learning,', 'r,', 'git/github', '##', 'interests', 'contributing', 'to', 'open-source', 'software', 'data', 'analytics', 'with', 'python', 'and', 'pandas', 'designing', 'data', 'visualization', 'web', 'apps', 'with', 'html,', 'css,', 'javascript,', 'and', 'd3', 'working', 'with', 'big', 'data', 'in', 'the', 'cloud', 'using', 'aws']\n",
      "\n",
      "WORD LIST AFTER CHARACTER PUNCTUATION REMOVAL\n",
      "['frank', 'n', 'stein', '', 'education', 'data', 'analytics', 'and', 'visualization', 'boot', 'camp', 'graduate', '', 'experience', 'creating', 'pivot', 'tables', 'and', 'vba', 'scripts', 'in', 'excel', 'modeling', 'and', 'forecasting', 'data', 'using', 'basic', 'statistics', 'writing', 'python', 'scripts', 'to', 'analyze', 'data', 'sets', 'from', 'files', 'and', 'apis', 'social', 'media', 'mining', 'using', 'python', 'working', 'with', 'mysql', 'and', 'mongodb', 'databases', 'developing', 'frontend', 'web', 'visualizations', 'using', 'html', 'css', 'bootstrap', 'd3', 'and', 'leafletjs', 'using', 'the', 'tableau', 'business', 'intelligence', 'software', 'performing', 'big', 'data', 'analytics', 'with', 'hadoop', 'working', 'with', 'machine', 'learning', 'algorithms', '', 'skills', 'microsoft', 'excel', 'python', 'javascript', 'htmlcss', 'api', 'interactions', 'social', 'media', 'mining', 'sql', 'hadoop', 'tableau', 'advanced', 'statistics', 'machine', 'learning', 'r', 'gitgithub', '', 'interests', 'contributing', 'to', 'opensource', 'software', 'data', 'analytics', 'with', 'python', 'and', 'pandas', 'designing', 'data', 'visualization', 'web', 'apps', 'with', 'html', 'css', 'javascript', 'and', 'd3', 'working', 'with', 'big', 'data', 'in', 'the', 'cloud', 'using', 'aws']\n",
      "\n",
      "WORD LIST AFTER STOP WORDS\n",
      "['frank', 'n', 'stein', '', 'education', 'data', 'analytics', 'visualization', 'boot', 'camp', 'graduate', '', 'experience', 'creating', 'pivot', 'tables', 'vba', 'scripts', 'excel', 'modeling', 'forecasting', 'data', 'basic', 'statistics', 'writing', 'python', 'scripts', 'analyze', 'data', 'sets', 'from', 'files', 'apis', 'social', 'media', 'mining', 'python', 'mysql', 'mongodb', 'databases', 'developing', 'frontend', 'web', 'visualizations', 'html', 'css', 'bootstrap', 'd3', 'leafletjs', 'the', 'tableau', 'business', 'intelligence', 'software', 'performing', 'big', 'data', 'analytics', 'hadoop', 'machine', 'learning', 'algorithms', '', 'skills', 'microsoft', 'excel', 'python', 'javascript', 'htmlcss', 'api', 'interactions', 'social', 'media', 'mining', 'sql', 'hadoop', 'tableau', 'advanced', 'statistics', 'machine', 'learning', 'r', 'gitgithub', '', 'interests', 'contributing', 'opensource', 'software', 'data', 'analytics', 'python', 'pandas', 'designing', 'data', 'visualization', 'web', 'apps', 'html', 'css', 'javascript', 'd3', 'big', 'data', 'the', 'cloud', 'aws']\n"
     ]
    }
   ],
   "source": [
    "# Calculate the Required Skills Match using Set Intersection\n",
    "print('REQUIRED SKILLS')\n",
    "print(resume & REQUIRED_SKILLS)\n",
    "\n",
    "# Calculate the Desired Skills Match using Set Intersection\n",
    "print('DESIRED SKILLS')\n",
    "print(resume & DESIRED_SKILLS)\n",
    "\n",
    "\n",
    "# Word Punctuation Cleaning\n",
    "word_list = [word for word in word_list if word not in string.punctuation]\n",
    "print('\\nWORD LIST AFTER PUNCTUATION REMOVAL')\n",
    "print(word_list)\n",
    "\n",
    "# Character Punctuation Cleaning\n",
    "word_list = [''.join(char for char in word if char not in string.punctuation) for word in word_list]\n",
    "print('\\nWORD LIST AFTER CHARACTER PUNCTUATION REMOVAL')\n",
    "print(word_list)\n",
    "\n",
    "# Clean Stop Words\n",
    "stop_words = [\"and\", \"with\", \"using\", \"##\", \"working\", \"in\", \"to\"]\n",
    "word_list = [word for word in word_list if word not in stop_words]\n",
    "print('\\nWORD LIST AFTER STOP WORDS')\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "Replace this with your clear explanation of what happens in the cell below.\n",
    "Be sure to explain the following:\n",
    "\n",
    "* How was the `word_count` dictionary initialized, what were in initial key values, and how were they set?\n",
    "\n",
    "\n",
    "It uses the .fromkeys fucntion to set zero values for all the values in the word list into the word_count dictionary. \n",
    "\n",
    "* Explain the logic behind incrementing the world count value using the `for loop`. Be sure to explain how to reference the word key in the `word_count` dictionary\n",
    "  The uses a ford loop to iterate through every value in the word_list and add one to the word_count for every value in the word_list. \n",
    "\n",
    "\n",
    "* Collections.counter is optional, but explain the difference between the `for loop` and using `Counter`\n",
    "\n",
    "This just uses a built in counter function which counts all entries in the dictionary just as the for loop iterates through the list and adds one for each entry. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Top 10 Words\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "# Resume Word Count\n",
    "# ==========================\n",
    "# Initialize a dictionary with default values equal to zero\n",
    "word_count = {}.fromkeys(word_list, 0)\n",
    "\n",
    "# Loop through the word list and count each word.\n",
    "for word in word_list:\n",
    "    word_count[word] += 1\n",
    "# print(word_count)\n",
    "\n",
    "# Bonus using collections.Counter\n",
    "word_counter = Counter(word_list)\n",
    "# print(word_counter)\n",
    "\n",
    "# Comparing both word count solutions\n",
    "print(word_count == word_counter)\n",
    "\n",
    "# Top 10 Words\n",
    "print(\"Top 10 Words\")\n",
    "print(\"=============\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace this with your clear explanation of what happens in the cell below. Which column was sorted and how? How was the top ten selected? Does that explain the significance of `[:10]`?\n",
    "\n",
    "As a bonus, explain how you would get rid of the blank token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: data                 Count: 7\n",
      "Token: python               Count: 4\n",
      "Token: analytics            Count: 3\n",
      "Token: visualization        Count: 2\n",
      "Token: scripts              Count: 2\n",
      "Token: excel                Count: 2\n",
      "Token: statistics           Count: 2\n",
      "Token: social               Count: 2\n",
      "Token: media                Count: 2\n",
      "Token: mining               Count: 2\n"
     ]
    }
   ],
   "source": [
    "# Sort words by count and print the top 10\n",
    "sorted_words = []\n",
    "for word in sorted(word_count, key=word_count.get, reverse=True)[:10]:\n",
    "    print(f\"Token: {word:20} Count: {word_count[word]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
